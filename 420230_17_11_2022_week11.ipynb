{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6Lrs4eUITKe",
        "outputId": "f8f2aec4-af46-4820-aad0-7b7c15c135c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability:  {'A': {True: {'C': {True: {'D': {True: 0.96875, False: 0.96}}, False: {'D': {True: 0.25, False: 0.2153846153846154}}}}, False: {'C': {True: {'D': {True: 0.03125, False: 0.04}}, False: {'D': {True: 0.75, False: 0.7846153846153846}}}}}}\n",
            "\n",
            "probability:  {'A': {True: {'B': {True: {'C': {True: 0.6292134831460674, False: 0.0547945205479452}}, False: {'C': {True: 0.33707865168539325, False: 0.1643835616438356}}}}, False: {'B': {True: {'C': {True: 0.0, False: 0.0}}, False: {'C': {True: 0.033707865168539325, False: 0.7808219178082192}}}}}}\n",
            "\n",
            "probability:  {'C': {True: {'D': {True: {'E': {True: 0.9782608695652174, False: 0.7307692307692307}}, False: {'E': {True: 0.8888888888888888, False: 0.015873015873015872}}}}, False: {'D': {True: {'E': {True: 0.021739130434782608, False: 0.2692307692307692}}, False: {'E': {True: 0.1111111111111111, False: 0.9841269841269841}}}}}}\n",
            "\n",
            "probability:  {'B': {True: {'C': {True: {'D': {True: {'E': {True: 0.6304347826086957, False: 0.46153846153846156}}, False: {'E': {True: 0.5555555555555556, False: 0.0}}}}, False: {'D': {True: {'E': {True: 0.0, False: 0.038461538461538464}}, False: {'E': {True: 0.037037037037037035, False: 0.031746031746031744}}}}}}, False: {'C': {True: {'D': {True: {'E': {True: 0.34782608695652173, False: 0.2692307692307692}}, False: {'E': {True: 0.3333333333333333, False: 0.015873015873015872}}}}, False: {'D': {True: {'E': {True: 0.021739130434782608, False: 0.23076923076923078}}, False: {'E': {True: 0.07407407407407407, False: 0.9523809523809523}}}}}}}}\n",
            "\n",
            "probability:  {'D': {True: {'E': {True: {'C': {True: 0.5056179775280899, False: 0.0136986301369863}}, False: {'C': {True: 0.21348314606741572, False: 0.0958904109589041}}}}, False: {'E': {True: {'C': {True: 0.2696629213483146, False: 0.0410958904109589}}, False: {'C': {True: 0.011235955056179775, False: 0.8493150684931506}}}}}}\n",
            "\n",
            "probability:  {'A': {True: {'C': {True: {'D': {True: 0.96875, False: 0.96}}, False: {'D': {True: 0.25, False: 0.21538461538461537}}}}, False: {'C': {True: {'D': {True: 0.03125, False: 0.04}}, False: {'D': {True: 0.75, False: 0.7846153846153846}}}}}}\n",
            "\n",
            "probability:  {'A': {True: {'B': {True: {'C': {True: 0.6292134831460675, False: 0.0547945205479452}}, False: {'C': {True: 0.3370786516853933, False: 0.1643835616438356}}}}, False: {'B': {True: {'C': {True: 0.0, False: 0.0}}, False: {'C': {True: 0.03370786516853933, False: 0.7808219178082192}}}}}}\n",
            "\n",
            "probability:  {'C': {True: {'D': {True: {'E': {True: 0.9782608695652173, False: 0.7307692307692307}}, False: {'E': {True: 0.8888888888888888, False: 0.015873015873015876}}}}, False: {'D': {True: {'E': {True: 0.021739130434782605, False: 0.2692307692307692}}, False: {'E': {True: 0.1111111111111111, False: 0.9841269841269842}}}}}}\n",
            "\n",
            "probability:  {'B': {True: {'C': {True: {'D': {True: {'E': {True: 0.6304347826086956, False: 0.46153846153846156}}, False: {'E': {True: 0.5555555555555556, False: 0.0}}}}, False: {'D': {True: {'E': {True: 0.0, False: 0.038461538461538464}}, False: {'E': {True: 0.037037037037037035, False: 0.03174603174603175}}}}}}, False: {'C': {True: {'D': {True: {'E': {True: 0.3478260869565217, False: 0.2692307692307692}}, False: {'E': {True: 0.3333333333333333, False: 0.015873015873015876}}}}, False: {'D': {True: {'E': {True: 0.021739130434782605, False: 0.23076923076923078}}, False: {'E': {True: 0.07407407407407407, False: 0.9523809523809524}}}}}}}}\n",
            "\n",
            "probability:  {'D': {True: {'E': {True: {'C': {True: 0.5056179775280899, False: 0.0136986301369863}}, False: {'C': {True: 0.21348314606741572, False: 0.0958904109589041}}}}, False: {'E': {True: {'C': {True: 0.2696629213483146, False: 0.0410958904109589}}, False: {'C': {True: 0.011235955056179775, False: 0.8493150684931506}}}}}}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import itertools, copy, random\n",
        "\n",
        "class RandomVariable:\n",
        "    '''\n",
        "    Class to hold metadata about each random variable.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, name, denotion, values, parents, children, cpt, topo_index):\n",
        "        self.name = name\n",
        "        self.denotion = denotion\n",
        "        self.values = values\n",
        "        self.parents = parents\n",
        "        self.children = children\n",
        "        self.cpt = cpt\n",
        "        self.topo_index = topo_index\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.name\n",
        "    \n",
        "    def call_build_distribution(self):\n",
        "        if self.parents:\n",
        "            dis = self.build_distribution(self.parents, 0)\n",
        "            cpt = {self.denotion:{value:copy.deepcopy(dis) for value in self.values}}\n",
        "        else:\n",
        "            cpt = {self.denotion:{value:0 for value in self.values}}\n",
        "        self.cpt = cpt\n",
        "        return \n",
        "    \n",
        "    def build_distribution(self, rvars, index):\n",
        "        if (index+1) == len(rvars):\n",
        "            iter_dis = {rvars[index].denotion:{value:0 for value in rvars[index].values}}\n",
        "            return iter_dis\n",
        "        else:\n",
        "            next_iter_dict = self.build_distribution(rvars, index+1)\n",
        "            iter_dis = {rvars[index].denotion:{value:copy.deepcopy(next_iter_dict) for value in rvars[index].values}}\n",
        "            return iter_dis\n",
        "\n",
        "    def display_node(self):\n",
        "        print('Name: ', self.name)\n",
        "        print('Denoted by: ', self.denotion)\n",
        "        print('Values: ', self.values)\n",
        "        print('Parents: ', [parent.name for parent in self.parents or []])\n",
        "        print('Children: ', [child.name for child in self.children or []])\n",
        "        print(\"CPT: \")\n",
        "        print(self.cpt)\n",
        "\n",
        "class BayesianNetwork():\n",
        "    '''\n",
        "    Bayesian network class to hold the network of nodes.\n",
        "    It extends the itertools class to make use of combinations method by overriding it.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, random_vars):\n",
        "        self.random_vars = random_vars\n",
        "\n",
        "    \n",
        "    def combinations(self, n, item_list):\n",
        "        single_list = [__ for _ in item_list for __ in _]\n",
        "        combs = itertools.combinations(single_list, n)\n",
        "        valid_combs = []\n",
        "        for comb in combs:\n",
        "            flag = False\n",
        "            for sub_list in item_list:\n",
        "                for comb_2 in itertools.combinations(comb, 2):\n",
        "                    if all(x in sub_list for x in comb_2):\n",
        "                        flag = True\n",
        "                        break\n",
        "                if flag:\n",
        "                    break\n",
        "            if not flag:\n",
        "                valid_combs.append(dict(comb))\n",
        "        return valid_combs\n",
        "    \n",
        "    def build_distribution(self, rvars, index):\n",
        "        if (index+1) == len(rvars):\n",
        "            iter_dis = {rvars[index].denotion:{value:0 for value in rvars[index].values}}\n",
        "            return iter_dis\n",
        "        else:\n",
        "            next_iter_dict = self.build_distribution(rvars, index+1)\n",
        "            iter_dis = {rvars[index].denotion:{value:copy.deepcopy(next_iter_dict) for value in rvars[index].values}}\n",
        "            return iter_dis\n",
        "\n",
        "\n",
        "    def enum_ask(self, query, evidence):\n",
        "        query_list = [[(rv.denotion,value) for value in rv.values] for rv in query+evidence]\n",
        "        query_combinations = self.combinations(len(query+evidence), query_list)\n",
        "        distribution = self.build_distribution(query+evidence, 0)\n",
        "        self.call_enum_all(query_combinations, distribution)\n",
        "        self.normalize(distribution, query_combinations, query)\n",
        "        return distribution\n",
        "    \n",
        "    def call_enum_all(self, query_combinations, distribution):\n",
        "        for query in query_combinations:\n",
        "            prob_dis = distribution \n",
        "            query_items = list(query.items())\n",
        "            for i in range(len(query)-1):\n",
        "                prob_dis = prob_dis[query_items[i][0]][query_items[i][1]]\n",
        "            i+=1\n",
        "            prob_dis[query_items[i][0]][query_items[i][1]] = self.enum_all(query)\n",
        "        return \n",
        "    \n",
        "    def enum_all(self, query):\n",
        "        marginilaise_vars = [rv for rv in self.random_vars if rv.denotion not in query.keys()]\n",
        "        marginalize_query_list = [[(rv.denotion,value) for value in rv.values] for rv in marginilaise_vars]\n",
        "        marg_query_comb = self.combinations(len(marginilaise_vars), marginalize_query_list)\n",
        "        new_queries = [copy.deepcopy(query|marg_query) for marg_query in marg_query_comb]\n",
        "        total_prob = 0\n",
        "        for que in new_queries:\n",
        "            marg_prob = 1\n",
        "            for rv in self.random_vars:\n",
        "                prob = rv.cpt[rv.denotion][que[rv.denotion]]\n",
        "                for parent in rv.parents or []:\n",
        "                    prob = prob[parent.denotion][que[parent.denotion]]\n",
        "                marg_prob = marg_prob*prob\n",
        "            total_prob += marg_prob\n",
        "        return total_prob\n",
        "\n",
        "    def normalize(self, distribution, query_combinations, query_vars, flag=True):\n",
        "        query_vars = [var.denotion for var in query_vars]\n",
        "        normalize_dict = {}\n",
        "        for comb in query_combinations:\n",
        "            key = ''\n",
        "            value = distribution\n",
        "            for item in comb.items():\n",
        "                if not flag:\n",
        "                    value = value[item[0].denotion][item[1]]\n",
        "                else:\n",
        "                    value = value[item[0]][item[1]]\n",
        "                # if not item[0] in query_vars:\n",
        "                if not flag:\n",
        "                    if not item[0].denotion in query_vars:\n",
        "                        key += item[0].denotion+str(item[1])\n",
        "                else: \n",
        "                    if not item[0] in query_vars:\n",
        "                        key += str(item[0])+str(item[1])\n",
        "            if key not in normalize_dict.keys():\n",
        "                normalize_dict[key] = value\n",
        "            else:\n",
        "                normalize_dict[key] += value\n",
        "        for comb in query_combinations:\n",
        "            key = ''\n",
        "            value = distribution\n",
        "            items = list(comb.items())\n",
        "            for i in range(len(items)-1):\n",
        "                if not flag:\n",
        "                    value = value[items[i][0].denotion][items[i][1]]\n",
        "                else:\n",
        "                    value = value[items[i][0]][items[i][1]]\n",
        "                if not flag:\n",
        "                    if not items[i][0].denotion in query_vars:\n",
        "                        key += items[i][0].denotion+str(items[i][1])\n",
        "                else: \n",
        "                    if not items[i][0] in query_vars:\n",
        "                        key += str(items[i][0])+str(items[i][1])\n",
        "            i+=1\n",
        "            key += str(items[i][0])+str(items[i][1])\n",
        "            if not flag:\n",
        "                value[items[i][0].denotion][items[i][1]] = (value[items[i][0].denotion][items[i][1]]/normalize_dict[key])\n",
        "            else:\n",
        "                value[items[i][0]][items[i][1]] = (value[items[i][0]][items[i][1]]/normalize_dict[key])\n",
        "\n",
        "    def ml_query(self, queries, samples):\n",
        "        samples = list(samples.items())\n",
        "        for query in queries:\n",
        "            distribution = self.build_distribution(query[0]+query[1], 0)\n",
        "            query_list = [[(rv,value) for value in rv.values] for rv in query[0]+query[1]]\n",
        "            combinations = self.combinations(len(query[0]+query[1]), query_list)\n",
        "            for comb in combinations:\n",
        "                prob_dict = distribution\n",
        "                fav_indices = [_ for _ in range(len(samples))]\n",
        "                evidence_indices = [_ for _ in range(len(samples))]\n",
        "                comb = list(comb.items())\n",
        "                for index in range(len(comb)):\n",
        "                    if index != (len(comb)-1):\n",
        "                        prob_dict = prob_dict[comb[index][0].denotion][comb[index][1]]\n",
        "                    fav_indices = [_ for _ in fav_indices if samples[_][0][comb[index][0].topo_index-1] == comb[index][1]]\n",
        "                    if comb[index][0] in query[1]:\n",
        "                        evidence_indices = [_ for _ in evidence_indices if samples[_][0][comb[index][0].topo_index-1] == comb[index][1]]\n",
        "                fav_choices = 0\n",
        "                for ind in fav_indices:\n",
        "                    fav_choices += samples[ind][1]\n",
        "                evidence_choices = 0\n",
        "                for ind in evidence_indices:\n",
        "                    evidence_choices += samples[ind][1]\n",
        "                prob = fav_choices/evidence_choices\n",
        "                prob_dict[comb[index][0].denotion][comb[index][1]] = prob\n",
        "            print('probability: ', distribution)\n",
        "            print()\n",
        "\n",
        "    def map_query(self, queries, samples):\n",
        "        samples = list(samples.items())\n",
        "        for query in queries:\n",
        "            distribution = self.build_distribution(query[0]+query[1], 0)\n",
        "            query_list = [[(rv,value) for value in rv.values] for rv in query[0]+query[1]]\n",
        "            combinations = self.combinations(len(query[0]+query[1]), query_list)\n",
        "            for comb in combinations:\n",
        "                prob_dict = distribution\n",
        "                fav_indices = [_ for _ in range(len(samples))]\n",
        "                comb = list(comb.items())\n",
        "                for index in range(len(comb)):\n",
        "                    if index != (len(comb)-1):\n",
        "                        prob_dict = prob_dict[comb[index][0].denotion][comb[index][1]]\n",
        "                    fav_indices = [_ for _ in fav_indices if samples[_][0][comb[index][0].topo_index-1] == comb[index][1]]\n",
        "                fav_choices = 0\n",
        "                for ind in fav_indices:\n",
        "                    fav_choices += samples[ind][1]\n",
        "                total_choices = 0\n",
        "                for ind in range(len(samples)):\n",
        "                    total_choices += samples[ind][1]\n",
        "                prob = fav_choices/total_choices\n",
        "                prob_dict[comb[index][0].denotion][comb[index][1]] = prob\n",
        "            self.normalize(distribution, combinations, query[0], False)\n",
        "            print('probability: ', distribution)\n",
        "            print()\n",
        "                    \n",
        "def main():\n",
        "    a = RandomVariable('A', 'A', [True, False], None, None, None, 1)\n",
        "    b = RandomVariable('B', 'B', [True, False], None, None, None, 2)\n",
        "    c = RandomVariable('C', 'C', [True, False], None, None, None, 3)\n",
        "    d = RandomVariable('D', 'D', [True, False], None, None, None, 4)\n",
        "    e = RandomVariable('E', 'E', [True, False], None, None, None, 5)\n",
        "    a.children = [c]\n",
        "    b.children = [c]\n",
        "    c.parents = [a, b]\n",
        "    c.children = [d,e]\n",
        "    d.parents = [c]\n",
        "    e.parents = [e]\n",
        "    bayes_net = BayesianNetwork([a,b,c,d,e])\n",
        "\n",
        "    samples = {\n",
        "        (0,0,0,1,0):5, (0,0,0,0,1):1, (0,0,0,1,1):1, \n",
        "        (0,0,0,0,0):50, (0,0,1,1,0):1, (0,0,1,0,1):1,\n",
        "        (0,0,1,1,1):1, (0,0,1,0,0):0, (1,0,0,1,0):1,\n",
        "        (1,0,0,0,1):1, (1,0,0,1,1):0, (1,0,0,0,0):10, \n",
        "        (1,0,1,1,0):6, (1,0,1,0,1):8, (1,0,1,1,1):15,\n",
        "        (1,0,1,0,0):1, (1,1,0,1,0):1, (1,1,0,0,1):1,\n",
        "        (1,1,0,1,1):0, (1,1,0,0,0):2, (1,1,1,1,0):12,\n",
        "        (1,1,1,0,1):15, (1,1,1,1,1):29, (1,1,1,0,0):0\n",
        "    }\n",
        "    queries = [[[a], [c,d]], [[a,b], [c]], [[c], [d,e]], [[b,c], [d,e]], [[d,e], [c]]]\n",
        "    bayes_net.ml_query(queries, samples)\n",
        "    bayes_net.map_query(queries, samples)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ]
}